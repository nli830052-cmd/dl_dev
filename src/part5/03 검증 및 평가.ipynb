{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e57024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2a0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n"
     ]
    }
   ],
   "source": [
    "# 0. 장치설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816b6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터준비\n",
    "# 1.1 데이터 전처리\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,),(0.5,))\n",
    "    \n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "# 1.2 데이터 다운로드, 로딩\n",
    "training_set = torchvision.datasets.FashionMNIST( #데이터셋은 이미 만들어져옴(근데 회사에서는 dataset직접 만들어야함,)\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True, # 없으면 다운로드 행라 없으면 하지말라\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 1.3 데이터로더 생성\n",
    "training_loader = DataLoader(\n",
    "    dataset = training_set,\n",
    "    batch_size = 64,\n",
    "    shuffle=True # 한개 이미지가 옆에 다른이미지와 상관없어서 shuffle 상관 X \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87627f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.모델 클래스 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super(MLP,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x): # x:입력데이터\n",
    "        x = self.flatten(x)\n",
    "        x = self.layers(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0a7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 모델 생성,모델을 cuda 즉, gpu로 이동하겠다.\n",
    "# model = MLP() # MLP object 생성 \n",
    "model = MLP().to(device) # cuda 메모리에 보내겠다.\n",
    "\n",
    "# 2.2 손실함수,옵티마이저 생성\n",
    "loss_fn = nn.CrossEntropyLoss() # 오차 구하는 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) # lr 은 적당히로 해야하는데 적당히를 모름\n",
    "# lr 이 작을수록 천천히 내려감, 시간 많이 걸리지만,발산확률이 젤 작음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968a27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.검증용 데이터 다운로드, 데이터로더 생성\n",
    "validation_set = torchvision.datasets.FashionMNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    dataset=validation_set,\n",
    "    batch_size=64,\n",
    "    shuffle=False # 검증용데이터는 shuffle X --> False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20251226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 938/938 [00:22<00:00, 42.25it/s, train_loss=0.49] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary | Train Loss: 0.4885 | Val Loss : 0.4492 | Val Acc : 83.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 938/938 [00:21<00:00, 43.20it/s, train_loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary | Train Loss: 0.4027 | Val Loss : 0.4127 | Val Acc : 84.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 938/938 [00:22<00:00, 42.10it/s, train_loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Summary | Train Loss: 0.3680 | Val Loss : 0.3895 | Val Acc : 86.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 938/938 [00:21<00:00, 42.82it/s, train_loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary | Train Loss: 0.3452 | Val Loss : 0.3822 | Val Acc : 86.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 938/938 [00:20<00:00, 45.38it/s, train_loss=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Summary | Train Loss: 0.3251 | Val Loss : 0.3625 | Val Acc : 87.25%\n",
      "\n",
      " Finished Training!!! \n"
     ]
    }
   ],
   "source": [
    "# 4.훈련 및 검증 루프\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # 여기서부터 훈련\n",
    "    model.train() # 모델을 훈련 모드로 설정\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(training_loader,desc=f'Epoch {epoch+1} [Train]')\n",
    "    \n",
    "    for dataset in progress_bar: #6만/64 횟수만큼 반복\n",
    "        # 학습에 필요한 데이터(배치) 준비\n",
    "        input_data,labels = dataset\n",
    "        input_data, labels = input_data.to(device),labels.to(device)\n",
    "\n",
    "        # 진짜 여기서부터 학습 시작\n",
    "        # 실제 학습은 optimizer가 함\n",
    "        optimizer.zero_grad()\n",
    "        outputs= model(input_data)\n",
    "        loss=loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # backward,step이 반복됨\n",
    "\n",
    "        # 여기까지 1 batch 데이터의 학습 종료\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'train_loss' : running_loss/(progress_bar.n+1)}) # n:횟수\n",
    "    \n",
    "    # 에폭별 평균 오차 출력\n",
    "    avg_train_loss =running_loss/len(training_loader)\n",
    "\n",
    "    # --- 검증 루프---\n",
    "    running_vloss = 0.0 # 초기값\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 검증 모드로 변경\n",
    "    # <주의> 검증모드는 순전파만 해야함(즉, 결과값만 뽑아내야함), 역전파를 막아야함!!\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 기울기 계산을 비활성화\n",
    "    with torch.no_grad(): # 역전파 하지마라\n",
    "        for vdataset in validation_loader: # 반복 => 1만/64\n",
    "            vinputs, vlabels = vdataset\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "            # 순전파: 예측값 추출(64,10)\n",
    "            voutputs = model(vinputs) # 결과가 (64,10)으로 나옴\n",
    "            \n",
    "            # 출력용 손실을 계산하겠다\n",
    "            vloss= loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss.item() #손실을 누적(합) => 평균\n",
    "            \n",
    "            # 정확도 계산\n",
    "            # 예측값 추출 0~9, 원래답: 0~9 --> 64개\n",
    "            _,predicted =torch.max(input=voutputs,dim=1) \n",
    "            # 안쓸껀데 erro는 안나야하니까 _써야함\n",
    "            # tensor니까 tensor 를 다루는 torch로 max 때려야함\n",
    "\n",
    "            total += vlabels.size(0)\n",
    "            # 갯수 누적\n",
    "            # 64를 적는 하드코딩을 하면 안됨\n",
    "            \n",
    "            # 정확도 계산 누적한다.\n",
    "            correct += (predicted==vlabels).sum().item() # 맞은갯수 추출(64개 가운데)\n",
    "    #평균 손실\n",
    "    avg_val_loss = running_vloss / len(validation_loader)\n",
    "    \n",
    "    #백분위로 출력\n",
    "    accuracy = correct/total*100 \n",
    "\n",
    "    # epoch for문 \n",
    "    print(f'Epoch {epoch+1} Summary | Train Loss: {avg_train_loss:.4f} | Val Loss : {avg_val_loss:.4f} | Val Acc : {accuracy:.2f}%')\n",
    "\n",
    "# end for Train finished\n",
    "print('\\n Finished Training!!! ')\n",
    "\n",
    "    # <주의> 1epoc 가 끝나고 검증해야함, 한번에 검증 하는게 아님, 그래야 제대로 학습하는지 알 수 있음\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# torch.max(a,b,c): 최대값 찾을때 사용\n",
    "x = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "x \n",
    "# 1.max(input) => return tensor(value)\n",
    "print(torch.max(x))\n",
    "print(torch.max(x).item())\n",
    "\n",
    "# 1.max(input,dim) # NamedTuple(values,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d0470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 50, 35]) tensor([0, 1, 0])\n",
      "tensor([35, 50,  9]) tensor([2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1.max(input,dim) # NamedTuple(values,index)\n",
    "\n",
    "x = torch.tensor([\n",
    "    [10,2 ,35], # 1행\n",
    "    [4 ,50,6], # 2행\n",
    "    [7 ,8, 9]   # 3행\n",
    "])\n",
    "values,indices = torch.max(x,dim=0) # 열끼리 비교\n",
    "print(values,indices)\n",
    "values,indices = torch.max(x,dim=1) # 행끼리 비교\n",
    "print(values,indices)\n",
    "\n",
    "\n",
    "# 각 열마다 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Docker Venv)",
   "language": "python",
   "name": "docker_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
