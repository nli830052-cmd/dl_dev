{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1f5b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# cu가 안뜨면 CPU버전이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07e1fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Nov  4 2025, 08:48:33) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# 3.13 버전 사용 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fd2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "# CUDA(GPU) 사용 가능 여부 확인 -->주석자체가 프롬프트다.\n",
    "# 셀에 주석을 잘 걸어놓으면 좋은 코드가 나온다.\n",
    "import torch\n",
    "print(torch.cuda.is_available()) # return True or False --> 조건식 OK\n",
    "\n",
    "# GPU 이름 확인\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60da2059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용가능한 GPU 수 : 1\n",
      "현재 사용 중인 GPU 인덱스 : 0\n",
      "Current GPU Name: NVIDIA GeForce GTX 1660 SUPER\n",
      "Current GPU Memory: 6.441992192 GB\n",
      "\\CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# 3. GPU가 사용 가능한 경우에만, 관련된 상세 정보 출력\n",
    "# 코드 기억해야함\n",
    "# 파란색 function 다 외워야 함\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용가능한 GPU 수 :\", torch.cuda.device_count()) # 현장가면 엄청 많음\n",
    "    current_gpu_index = torch.cuda.current_device()\n",
    "    print(\"현재 사용 중인 GPU 인덱스 :\", current_gpu_index) # GPU가 여러개일땐 인덱스 변경 가능, 분산처리도 가능\n",
    "    print('Current GPU Name:', torch.cuda.get_device_name(current_gpu_index))\n",
    "    print('Current GPU Memory:', torch.cuda.get_device_properties(current_gpu_index).total_memory / 1e9, \"GB\")\n",
    "    print(f'\\CUDA version: {torch.version.cuda}')\n",
    "\n",
    "else:\n",
    "    print(\"GPU가 사용 불가능합니다.\")\n",
    "\n",
    "#GPU의 메모리 사용량 확인\n",
    "#중요한건 :AI를 제어하는 개발자가 되야함, 그래야 좋은 개발자임,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e396259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "Type of x: torch.LongTensor\n",
      "Type of x: torch.int64\n",
      "Size of x: torch.Size([3])\n",
      "Device of x: cpu\n"
     ]
    }
   ],
   "source": [
    "#4.간단한 텐서(Tensor) 생성 및 출력 \n",
    "import torch    \n",
    "x=torch.tensor([1,2,3]) # x는 변수: tensor라는 opject를 가지는 변수이다.\n",
    "                        # 텐서: 다차원배열(array)근데 nadarty는 아니다\n",
    "                    \n",
    "print(x)\n",
    "print(f'Type of x: {x.type()}')\n",
    "# print(f'Type of x: {x.dtype()}' --> 에러발생함\n",
    "print(f'Type of x: {x.dtype}')  # dtype은 원래 넘파이에 나오지만 다르다,device=CPU\n",
    "print(f'Size of x: {x.size()}')\n",
    "# print할때는cpu쓸수밖에 없음,\n",
    "print(f'Device of x: {x.device}')\n",
    "\n",
    "# 데이터가 일부는 cpu,일부는 gpu에 저장하면 학습할때 멈출수 있어서 위에 코드 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2 텐서를 GPU로 보내고 다시 가져오기\n",
    "# tensor를 다루려면 torch 가 필요하다.\n",
    "import time # 파이썬 내장용 , 원래 내장모듈을 먼저 import하는게 빠르다.\n",
    "import torch # 파이외장 모듈\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "664fd117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. 장치(device)설정:GPU가 있으면,'cuda'를 없으면 'cpu'를 사용 \n",
    "# 여러개의 GPU가 있을경우엔 'cuda:0','cuda:1' 같은 식으로 지정 가능\n",
    "# 현재코드는 GPU가 한개인 경우로 가정 --> 'cuda'로 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\") # cuda 로 나왔다 결국 gpu 다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0c4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n",
      "torch.float16\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 2 텐서 생성: cpu생성(기본동작)\n",
    "cpu_tensor = torch.tensor([ # 오브젝트 구성: attribute & method\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "]\n",
    ",dtype=torch.float16 # 중요한 이유:  16으로 바꾸면 메모리가 2배로 줄어듭니다.\n",
    "                    # 근데 8은 오류남, 최소데이터수가 16임 / LLM 에서 되게 중요함\n",
    ")\n",
    "print(cpu_tensor) # 텐서 오브젝트 생성\n",
    "print(cpu_tensor.dtype) # 만약 1.0으로 고치면 전체 배열이 소수로 바뀜,float32로 출력 / 근데 이렇게 맡기면 안되고 dtpye직접 기정해야함\n",
    "\n",
    "print(cpu_tensor.device) # 얘가 어디에 저장되어 있는지 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0621a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0', dtype=torch.float16)\n",
      "이동 시간: 0.36204초\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# cpu -> gpu 로 옮기기\n",
    "start_time = time.time()\n",
    "moved_tensor = cpu_tensor.to(device) # Gpu로 보내라(복사해서 보낸다.) , RAM --> VRAM으로 복사해서 보내라(삭제가 X)\n",
    "end_time = time.time()\n",
    "\n",
    "print(moved_tensor) # 그냥 쿠다가 아니라 device='cuda:0' 이렇게 나옴\n",
    "\n",
    "print(f'이동 시간: {end_time - start_time:.5f}초') # 짧은시간에 옮겨졌다. 근데 시간은 걸린다 ,작은데이터라 / 큰데이터는 시간 더 걸림\n",
    "# 즉 한방에 데이터가 슥 옮겨질수 없다.\n",
    "print(cpu_tensor) # device 안나옴, 즉 아직 cpu에 남아있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf77b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "GPU 텐서 생성 시간: 0.01297 초\n"
     ]
    }
   ],
   "source": [
    "# GPU에서 직접 텐서 생성 가능\n",
    "# 이방법은 CPU 메모리를 거치지 않고 바로 GPU 메모리에 텐서 할당하여 더 효율적일 수 있다.\n",
    "if torch.cuda.is_available():\n",
    "    # GPU 사용 가능\n",
    "    start_time = time.time()\n",
    "    direct_gpu_tensor = torch.ones(2,3, device=device) # torch.ones()은 CPU 메모리에 텐서를 생성하고 device로 이동\n",
    "    end_time = time.time()\n",
    "    print(direct_gpu_tensor)\n",
    "    print(f\"GPU 텐서 생성 시간: {end_time - start_time:.5f} 초\") # 위에 cpu->gpu할때보다 속도 더 빨라짐\n",
    "else:\n",
    "    # GPU 사용 불가능\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a3f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 이동 시간: 0.00124초\n",
    "# 직접 생성 :0.00091 초 \n",
    "# gpu -> cpu  : 다시CPU로 옮기기\n",
    "cpu_to_tensor = moved_tensor.cpu() # method\n",
    "print(cpu_to_tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 텐서 중요 속성 다루기\n",
    "# 교재에 있는 코드는 의미는 없지만 속성들은 중요하니까 봐야함\n",
    "# 3X5 크기의 float32 타입의 텐서 생성,gpu 사용,미분가능\n",
    "# 텐서단위로 미분할 수 있다!!!\n",
    "import torch\n",
    "tensor_ = torch.randn(3,5,dtype=torch.float32,device=device, requires_grad=True)  # 신경망에 바로 들어가 사용 가능\n",
    "\n",
    "print(tensor_.requires_grad)\n",
    "print(tensor_.is_leaf) # 현재는 의미없다. 왜 ? 하나밖에 없어서 이미 나무에 잎이 하나밖에 없어서, 나중에 끝을 따질때가 있다.....\n",
    "                       # 그리고 leaf 가 여러개 있을수도 있다.\n",
    "                       # \n",
    "\n",
    "# 계산그래프:텐서와 텐서를 연산하도록 하는것\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Docker Venv)",
   "language": "python",
   "name": "docker_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
